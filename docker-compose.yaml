version: '3'
services:
  zookeeper:
    image: 'wurstmeister/zookeeper:latest'
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: 'wurstmeister/kafka:latest'
    ports:
      - '9093:9093'
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=LOCAL:PLAINTEXT,REMOTE:PLAINTEXT
      - KAFKA_LISTENERS=LOCAL://kafka:9093,REMOTE://kafka:9092
      - KAFKA_ADVERTISED_LISTENERS=LOCAL://localhost:9093,REMOTE://kafka:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_INTER_BROKER_LISTENER_NAME=REMOTE
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "kafka:9092"]
      interval: 5s
      timeout: 5s
      retries: 5
    depends_on:
      - zookeeper

  mongodb:
    image: 'mongo:latest'
    ports:
      - '27017:27017'
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017 --quiet
      interval: 5s
      timeout: 5s
      retries: 5

  inference:
    build: inference-service/.
    ports:
      - '8080:8080'
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    volumes:
      - ./inference-service/app/app.py:/usr/app/app.py
      - ./inference-service/app/openapi.yml:/usr/app/openapi.yml
      - ./logs/:/usr/app/logs

  exec_infer_jobs:
    image: tensorflow/serving:latest
    ports:
      - '8501:8501'
    depends_on:
      - inference
    command: ['--model_config_file=/tmp/models.config']
    environment:
      - MODEL_BASE_PATH=/opt/celonis_ml_challenge/inference_models/saved_models
    volumes:
      - ./:/opt/celonis_ml_challenge
      - ./inference_models/saved_models/models.config:/tmp/models.config